### Update Tweetpipe LLM credentials.
PUT http://localhost:3000/api/settings
Content-Type: application/json

{
  "provider": "google",
  "model": "gemini-1.5-pro",
  "apiKey": "",
  "mood": "funny, informative"
}


### Test the AI tweet generation from OCR chunk.
POST http://localhost:3000/api/tweet
Content-Type: application/json

[
  {
    "text": "View [9 t File Edit Selection EXPLORER v DATA-TABLE node modules > public v app api v cron route.ts > settings v tweet \nroute.ts .http favicon.ico globals.css layout.tsx page.tsx components > cultui Go p data-table .http U R route.ts ...\\cronUX route.ts ...\\tweet M texture-button src > app > api > cron > route.ts > [e] POST x import { latestOCR } from \"6)/ hooks/ use-ocr-data\" ; import { storeCronData } from \"6)/ lib/storage\"; const BASE URL = process. env . NODE ENV \" development\" • // localhos ? \"http. export const dynamic = \" force-dynamic\"; export const POST = async (req: Request) try { await latestOCR({ const latest ocr = if \n(!latest_ocr.data) { return Response.json( pagelndex: 0, page 1 2 3 4 5 6 7 8 9 10 data: { message: \"There was a problem fetching \nOCR. in it: status: 500 latest_ocr.data.map(callbackfn: (item const chunks = c audio-transcriptions-table.tsx data-table.tsx database-sidebar.tsx markdown.tsx ocr-data-table.tsx sql-autocomplete-input.tsx tweet-card.tsx tweet-list.tsx > hooks v lib > actions > hooks v storage index.ts > provider > TIMELINE 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 30 31 32 38 39 SEARCH > > console.log(message: \"Chunks length: fetch(input: - await const req = if (!req.ok) { • optional Parat GITLENS PROBLEMS addlssues : OUTPUT DEBUG CONSOLE route.ts ...\\tweet M Response(99152ms) X ocr-data-table.tsx HTTP/ 1.1 500 Internal Server Error vary: RSC, Next-Router-State-Tree, Next-Router-Pref etch, Next-Router-Segment-Prefetch content-type: application/json Date: sun, 02 Mar 2025 22: 16: 11 GMT Connection: close Transfer-Encoding: chunked \"message\": \"Error generating tweets.\" bash ollama PORTS 0226B TERMINAL POST /api/tweet [Function (anonymous)] 500 in 98855ms {\"message\" : \"Internal error. \"} POST /api/cron 500 in Compiled in 35ms p main* 0 09 needs reviewers @0A0 99146ms 147 S 99152ms Q Ln 16 col 24 Spaces: 2 UTE-8 CRLF { } TypeScript II Ninja O Go Live \nU Prettier"
  },
  {
    "text": "View [9 t File Edit Selection EXPLORER v DATA-TABLE node modules > public v app api v cron route.ts > settings v tweet \nroute.ts .http favicon.ico globals.css layout.tsx page.tsx components > cultui Go p data-table texture-button x .http U route.ts ...\\cron U src > app > api > cron > route.ts > [e] POST 9 13 14 15 16 17 18 19 20 21 22 23 24 30 31 32 38 39 42 43 44 46 SEARCH rt const POST = async (req: if (!latest_ocr.data) { return Response.json( data: { message: \"There in it: status: 500 route.ts ...\\tweet M Request) -9 { was a problem fetching OCR. \" latest_ocr.data.map(callbackfn: (item const chunks = . OcrRe console.log(message: \"Chunks length: optional Params: c 1 2 3 4 5 6 7 8 9 10 > > fetch(input: - await inii const req = if (!req.ok) { • (await req.json()) as { id: string; tweet: stri const res = console. log(message: \"Tweets: \" await storeCronData(tweets: res); optional Params: res), audio-transcriptions-table.tsx data-table.tsx database-sidebar.tsx markdown.tsx ocr-data-table.tsx sql-autocomplete-input.tsx tweet-card.tsx tweet-list.tsx > hooks v lib > actions > hooks v storage index.ts > provider > TIMELINE return Response.json(data: { catch (error) { console.log(message: error) return Response.json(data: { PROBLEMS addlssues : OUTPUT DEBUG CONSOLE [Function (anonymous)] 500 in 98855ms message: \"Tweets generated\" message: \"Internal error\" } , PORTS TERMINAL GITLENS 0226B route.ts ...\\tweet M Response(99152ms) X ocr-data-table.tsx HTTP/ 1.1 500 Internal Server Error vary: RSC, Next-Router-State-Tree, Next-Router-Pref etch, Next-Router-Segment-Prefetch content-type: application/json Date: sun, 02 Mar 2025 22: 16: 11 GMT Connection: close Transfer-Encoding: chunked \"message\": \"Error generating tweets.\" bash ollama POST /api/tweet {\"message\" : \"Internal error. \"} POST /api/cron 500 in Compiled in 35ms p main* 0 09 needs reviewers @0A0 99146ms 147 S 99152ms Q Ln 16 col 24 Spaces: 2 UTE-8 CRLF O TypeScript II Ninja O Go Live U Prettier"
  },
  {
    "text": "View [9 t File Edit Selection EXPLORER v DATA-TABLE node modules > public v app api v cron route.ts > settings v tweet \nroute.ts .http favicon.ico globals.css layout.tsx page.tsx components > cultui Go p data-table route.ts ...\\tweet M X €0 x .http \nU route.ts ...\\cron U src > app > api > tweet > route.ts > [e] POST 1 2 3 4 5 6 7 8 9 10 ; 11 12 ; 13 14 ; 15 : 16 : 17 : 18 : 19 20 ; 21 : 22 23 24 25 : 26 : 27 : 28 : SEARCH You, 2 seconds ago | 1 author (You) import { 01 lama } from 24.8k (gzippe, \" ollama-ai-provider\" ; import { google } from \"ä)ai-sdk/googte\" ; 26.5k (gzipped: 8 import { generateObject, generateText } from \"a i\" 90.4k (l import { z } from \"zod\"; 61k (gzipped: 14.5k) export const dynamic = \" force-dynamic\"; export const POST = async (req: Request) { try { (await req.json()) as { text: string H]; const chat = 1 2 3 4 5 6 7 8 9 10 console.log(message: \"Chat\", optional Params: chat); audio-transcriptions-table.tsx data-table.tsx database-sidebar.tsx markdown.tsx ocr-data-table.tsx sql-autocomplete-input.tsx tweet-card.tsx tweet-list.tsx > hooks v lib > actions > hooks v storage index.ts > provider > TIMELINE const { object } = await generateObject(options: { temperature: 0.5, \" array\" output : schema: z. object(shape: { tweet: z . stringC) second ago Uncommitted ch You, .describe(description: \"The content of tweet read) D, // model: 01 lama( \"llama3 . 2: latest\"), model: google(modelld: \"gemini-1.5-pro\") as any, 'You are a friendly A1 tweet bot. system: Your task is to summarize OCR text chunks and generate potential tweets for social media growth. If ill Do PROBLEMS addlssues : POST /api/tweet a chunk lacks sufficient context, not add remarks or explanations. OUTPUT DEBUG CONSOLE PORTS TERMINAL [Function (anonymous)] 500 in 98855ms {\"message\" : \"Internal error. \"} \ndo nothing. GITLENS You, 1 second ago route.ts ...\\tweet M Response(99152ms) X ocr-data-table.tsx HTTP/ 1.1 500 Internal Server Error vary: RSC, Next-Router-State-Tree, Next-Router-Pref etch, Next-Router-Segment-Prefetch content-type: application/json Date: sun, 02 Mar 2025 22: 16: 11 GMT Connection: close Transfer-Encoding: chunked \"message\": \"Error generating tweets.\" bash ollama POST /api/cron 500 in Compiled in 35ms p main* 0 09 needs reviewers @0A0 99146ms 147 S 99152ms 0226B Q Ln 19, col 20 Spaces: 2 UTE-8 CRLF { } TypeScript II Ninja O Go Live v/ Prettier"
  },
  {
    "text": "View [9 t File Edit Selection EXPLORER v DATA-TABLE node modules > public v app api v cron route.ts > settings v tweet \nroute.ts .http favicon.ico globals.css layout.tsx page.tsx components > cultui Go p data-table route.ts ...\\tweet M X €0 x .http \nU route.ts ...\\cron U src > app > api > tweet > route.ts > [e] POST 3 4 5 6 7 8 9 10 ; 11 12 ; 13 14 ; 15 : 16 : 17 : 18 : 19 21 \n: 22 23 24 25 : 26 : 27 : 28 : 29 30 ; 31 ; SEARCH import { generateObject, generateText } from \"a i\" import { z } from \"zod\"; 61k (gzipped: 14.5k) export const dynamic = \" force-dynamic\"; export const POST = async (req: Request) { try { 90. (await req.json()) as { text: string H]; const chat = console.log(message: \"Chat\", optional Params: chat); 1 2 3 4 5 6 7 8 9 10 audio-transcriptions-table.tsx data-table.tsx database-sidebar.tsx markdown.tsx ocr-data-table.tsx sql-autocomplete-input.tsx tweet-card.tsx tweet-list.tsx > hooks v lib > actions > hooks v storage index.ts > provider > TIMELINE const { object } = await generateObject(options: { \ntemperature: 0.5, \" array\" output : schema: z. object(shape: { tweet: z . stringC)l second ago Uncommitted ch You, .describe(description: \"The content of tweet read) D, // model: ollama(modelld: \"llama3 .2: latest\"), model: google( \"gemini-1.5-pro\") as any, -you are a friendly A1 tweet bot. system: Your task is to summarize OCR text chunks and generate potential tweets for social media growth. If a chunk lacks sufficient context, do nothing. Do not add remarks or explanations. Assume the tweet will be posted as -IS. prompt : IllGenerate an organictweetin under 200 characters. PROBLEMS OUTPUT DEBUG CONSOLE PORTS TERMINAL GITLENS route.ts ...\\tweet M Response(99152ms) X ocr-data-table.tsx HTTP/ 1.1 500 Internal Server Error vary: RSC, Next-Router-State-Tree, Next-Router-Pref etch, Next-Router-Segment-Prefetch content-type: application/json Date: sun, 02 Mar 2025 22: 16: 11 GMT Connection: close Transfer-Encoding: chunked \"message\": \"Error generating tweets.\" bash ollama addlssues: [Function (anonymous)] POST /api/tweet 500 in 98855ms {\"message\" : \"Internal error. \"} POST /api/cron 500 in Compiled in 35ms p main* 0 09 needs reviewers @0A0 99146ms 147 S 99152ms 0226B You, 1 second ago Q Ln 19, col 20 Spaces: 2 UTE-8 CRLF { } TypeScript II Ninja O Go Live v/ Prettier"
  },
  {
    "text": "x [9 t File Edit Selection EXPLORER v DATA-TABLE node modules > public v src v app v cron route.ts > settings v tweet route.ts .http favicon.ico globals.css layout.tsx page.tsx components > cultui View Go p data-table route.ts ...\\tweet 3, MX .http U route.ts ...\\cron U src > app > api > tweet > route.ts > [e] POST route.ts ...\\tweet 3, M Response(99152ms) X ocr-data-table.tsx 3 4 5 6 7 8 9 10 ; 11 12 ; 13 14 ; 15 : 16 : 17 : 18 : 19 : 21 : 22 23 ; 24 25 : 26 : 27 : 28 : 29 30 ; 31 ; SEARCH { generateObject, generateText } from \"a i\" { z } from \"zod\"; 61k (gzipped: 14.5k) . const dynamic = \"force-dynamic\"; . const POST = async (req: Request) { 90. 4k (gzippe:z— (await req.json()) as { text: string H]; )nst chat = msole.log(message: \"Chat\", optional Params: chat); 1 2 3 4 5 6 7 8 9 10 )nst { object } - - await temperature: 0.5, \" array\" output : No generateObject(options: overload matches this call. The Ias schema: z. object(shape. tweet: z .string() .describe(description: \"The content of tweet ready to p D, // \nmodel: ollama(modelld: \"llama3 .2: latest\"), model: google( \"gemini-1.5-pro\") las any, -you are a friendly A1 tweet bot. system: Your task is to summarize OCR text chunks and generate potential tweets for social media growth. If a chunk lacks sufficient context, do nothing. audio-transcriptions-table.tsx data-table.tsx database-sidebar.tsx markdown.tsx ocr-data-table.tsx sql-autocomplete-input.tsx tweet-card.tsx tweet-list.tsx > hooks v lib > actions > hooks v storage index.ts > provider > TIMELINE Do not add remarks or explanations. Assume the tweet will be posted as -IS. prompt : 200 characters. Generate an organictweetlnunder PROBLEMS OUTPUT DEBUG CONSOLE PORTS TERMINAL GITLENS HTTP/ 1.1 500 Internal Server Error vary: RSC, Next-Router-State-Tree, Next-Router-Pref etch, Next-Router-Segment-Prefetch content-type: application/json Date: sun, 02 Mar 2025 22: 16: 11 GMT Connection: close Transfer-Encoding: chunked \"message\": \"Error generating tweets.\" bash ollama addlssues: [Function (anonymous)] POST /api/tweet 500 in 98855ms {\"message\" : \"Internal error. \"} POST /api/cron 500 in Compiled in 35ms p main* 0 09 needs reviewers @3A0 99146ms 147 S 99152ms \n0226B C) Blame Paused Q Ln 23, Col 44 Spaces: 2 UTE-8 CRLF { } TypeScript II Ninja O Go Live U Prettier"
  }
]


### Manually trigger the cron workflow.
POST http://localhost:3000/api/cron
Content-Type: application/json


### Get cron tweet history.
GET http://localhost:3000/api/tweet
Content-Type: application/json



 

